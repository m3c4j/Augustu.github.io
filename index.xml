<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>主页 on 滴滴哒的技术分享</title><link>https://www.didida.top/</link><description>Recent content in 主页 on 滴滴哒的技术分享</description><generator>Hugo -- gohugo.io</generator><language>en-us</language><copyright>© Augustu Scofield 2021</copyright><lastBuildDate>Sun, 04 Apr 2021 23:06:29 +0800</lastBuildDate><atom:link href="https://www.didida.top/index.xml" rel="self" type="application/rss+xml"/><item><title>Introduction</title><link>https://www.didida.top/kubernetes/introduction/</link><pubDate>Tue, 13 Apr 2021 21:34:34 +0800</pubDate><guid>https://www.didida.top/kubernetes/introduction/</guid><description>Kubernetes 服务发现和负载均衡 存储编排 自动部署和回滚 自动完成装箱计算 自我修复 密钥与配置管理 Kubernetes 组件 控制平面组件（Control Plane Components）
kube-apiserver
etcd
kube-scheduler
kube-controller-manager
从逻辑上讲，每个控制器都是一个单独的进程， 但是为了降低复杂性，它们都被编译到同一个可执行文件，并在一个进程中运行。
节点控制器（Node Controller）
负责在节点出现故障时进行通知和响应。
副本控制器（Replication Controller）
负责为系统中的每个副本控制器对象维护正确数量的 Pod。
端点控制器（Endpoints Controller）
填充端点(Endpoints)对象(即加入 Service 与 Pod)。
服务帐户和令牌控制器（Service Account &amp;amp; Token Controllers）
为新的命名空间创建默认帐户和 API 访问令牌。
cloud-controller-manager
节点控制器（Node Controller）
用于在节点终止响应后检查云提供商以确定节点是否已被删除。
路由控制器（Route Controller）
用于在底层云基础架构中设置路由。
服务控制器（Service Controller）
用于创建、更新和删除云提供商负载均衡器。
Node 组件
节点组件在每个节点上运行，维护运行的 Pod 并提供 Kubernetes 运行环境。
kubelet
kube-proxy
容器运行时（Container Runtime）
Kubernetes 支持多个容器运行环境: Docker、 containerd、CRI-O 以及任何实现 Kubernetes CRI (容器运行环境接口)。
插件（Addons）
DNS Web 界面（仪表盘） 容器资源监控 集群层面日志 节点（node） Kubernetes 通过将容器放入在节点（Node）上运行的 Pod 中来执行你的工作负载。</description></item><item><title>Redis</title><link>https://www.didida.top/docker/redis/</link><pubDate>Tue, 13 Apr 2021 21:31:35 +0800</pubDate><guid>https://www.didida.top/docker/redis/</guid><description>Redis docker pull redis docker run --name redis-bench \ -v /home/Develop/data/redis/conf:/data \ -p 127.0.0.1:6379:6379 \ -d redis docker run --name redis-bench \ -p 127.0.0.1:6379:6379 \ -d redis Redis 集合(Set) 命令 描述 SADD key member1 [member2] 向集合添加一个或多个成员 SCARD key 获取集合的成员数 SDIFF key1 [key2] 返回第一个集合与其他集合之间的差异 SDIFFSTORE destination key1 [key2] 返回给定所有集合的差集并存储在 destination 中 SINTER key1 [key2] 返回给定所有集合的交集 SINTERSTORE destination key1 [key2] 返回给定所有集合的交集并存储在 destination 中 SISMEMBER key member 判断 member 元素是否是集合 key 的成员 SMEMBERS key 返回集合中的所有成员 SMOVE source destination member 将 member 元素从 source 集合移动到 destination 集合 SPOP key 移除并返回集合中的一个随机元素 SRANDMEMBER key [count] 返回集合中一个或多个随机数 SREM key member1 [member2] 移除集合中一个或多个成员 SUNION key1 [key2] 返回所有给定集合的并集 SUNIONSTORE destination key1 [key2] 所有给定集合的并集存储在 destination 集合中 SSCAN key cursor [MATCH pattern] [COUNT count] 迭代集合中的元素 ref: https://www.</description></item><item><title>Rabbitmq</title><link>https://www.didida.top/docker/rabbitmq/</link><pubDate>Tue, 13 Apr 2021 21:30:50 +0800</pubDate><guid>https://www.didida.top/docker/rabbitmq/</guid><description>RabbitMQ docker pull rabbitmq:management docker run --name rabbitmq-bench \ -p 127.0.0.1:15672:15672 \ -p 127.0.0.1:5672:5672 \ -p 127.0.0.1:15692:15692 \ -e RABBITMQ_DEFAULT_USER=admin \ -e RABBITMQ_DEFAULT_PASS=123456 \ -d rabbitmq:management exchange ref: https://www.rabbitmq.com/tutorials/tutorial-three-go.html
types:
direct
topic
headers
fanout
It just broadcasts all the messages it receives to all the queues it knows
queue producer consumer</description></item><item><title>Introduction</title><link>https://www.didida.top/operate-system/introduction/</link><pubDate>Tue, 13 Apr 2021 21:29:50 +0800</pubDate><guid>https://www.didida.top/operate-system/introduction/</guid><description>操作系统的主要功能 从资源管理器的观点来看，操作系统的任务是高效地管理整个系统的各个部分； 从扩展机的观点来看，其任务是为用户提供一台比物理计算机更易于使用的虚拟计算机； 系统调用 与进程有关，与文件系统有关
与进程的创建和终止有关 处理信号 针对文件读写 进行目录管理 对信息进行保护 用于时间管理 操作系统结构 整体结构
整个操作系统是一组函数的集合，其中每个函数在需要的时候可以去调用任何其他的函数
分层结构
把整个操作系统组织成一个层次结构，每一层软件都是在它的下层软件的基础上构造起来的
虚拟机
外核
外核程序管理资源分配
客户-服务器模型
消息请求回复
操作系统 进程管理 I/O设备管理 存储管理 文件管理 进程 通信
调度
时钟中断 非抢占式调度算法 抢占式调度算法
所有系统
公平 策略强制执行 平衡
批处理系统
吞吐量 周转时间 CPU利用率
非抢占式调度算法 先到先服务 最短作业优先 抢占式调度算法 最短剩余时间优先 三级调度 准入调度器 内存调度器 CPU调度器 交互式系统
响应时间 均衡性
两级调度： 内存调度 CPU调度
时间片轮转调度 优先级调度 多重队列 最短进程优先 保证调度算法 彩票调度算法 公平分享调度 实时系统
满足截至时间 可预测性
系统： 硬实时 软实时
时间： 周期性 非周期性</description></item><item><title>Mysql</title><link>https://www.didida.top/docker/mysql/</link><pubDate>Tue, 13 Apr 2021 21:27:42 +0800</pubDate><guid>https://www.didida.top/docker/mysql/</guid><description>mysql docker pull mysql:5.7 # 拉取 mysql 5.7 docker pull mysql # 拉取最新版mysql镜像 docker run -p 3306:3306 --name mysql-bench \ -v /run/media/mike/Data/Develop/data/mysql/tmp:/tmp \ -e MYSQL_ROOT_PASSWORD=123456 \ -d mysql docker run -p 127.0.0.1:3306:3306 --name mysql-bench \ -v /home/mike/Develop/data/mysql/conf:/etc/mysql \ -v /home/mike/Develop/data/mysql/mysql:/var/lib/mysql \ -v /home/mike/Develop/data/mysql/mysql-files:/var/lib/mysql-files \ -v /home/mike/Develop/data/mysql/logs:/var/log/mysql \ -e MYSQL_ROOT_PASSWORD=123456 \ -d mysql mysql -h 127.0.0.1 -P 3306 -u root -p 123456 ref: https://www.cnblogs.com/sablier/p/11605606.html
bench sysbench sysbench /usr/share/sysbench/oltp_read_write.lua \ --tables=5 \ --table_size=100 \ --mysql-user=root \ --mysql-password=123456 \ --mysql-host=127.</description></item><item><title>Monitor</title><link>https://www.didida.top/docker/monitor/</link><pubDate>Tue, 13 Apr 2021 21:26:52 +0800</pubDate><guid>https://www.didida.top/docker/monitor/</guid><description>Monitor docker pull prom/prometheus docker pull prom/node-exporter docker pull grafana/grafana docker run --name archlinux \ -p 127.0.0.1:9100:9100 \ -v /proc:/host/proc:ro \ -v /sys:/host/sys:ro \ -v /:/rootfs:ro \ --net=host \ -d prom/node-exporter docker run --name mysqld-exporter-mysql-bench \ -p 127.0.0.1:9104:9104 \ --link=mysql-bench:mysql \ -e DATA_SOURCE_NAME=&amp;#34;root:123456@(mysql:3306)/&amp;#34; \ -d prom/mysqld-exporter docker run --name prometheus \ -p 127.0.0.1:9090:9090 \ -v /home/mike/Develop/data/prometheus/conf/prometheus.yml:/etc/prometheus/prometheus.yml \ -d prom/prometheus docker run --name=grafana \ -p 127.0.0.1:3000:3000 \ -v /home/mike/Develop/data/grafana/data:/var/lib/grafana \ -d grafana/grafana # admin:admin -&amp;gt; admin:123456 # dashboard # 系统监控 1 Node Exporter for Prometheus Dashboard CN v20201010 https://grafana.</description></item><item><title>Gitlab</title><link>https://www.didida.top/docker/gitlab/</link><pubDate>Tue, 13 Apr 2021 21:25:16 +0800</pubDate><guid>https://www.didida.top/docker/gitlab/</guid><description>Gitlab docker run --name gitlab \ -p 127.0.0.1:22:22 \ -p 127.0.0.1:443:443 \ -p 127.0.0.1:80:80 \ -d gitlab/gitlab-ce docker run --name gitlab \ -p 127.0.0.1:22:22 \ -p 127.0.0.1:443:443 \ -p 127.0.0.1:80:80 \ --hostname gitlab.org \ -v /home/Mount/Develop/data/gitlab/etc:/etc/gitlab \ -v /home/Mount/Develop/data/gitlab/opt:/var/opt/gitlab \ -v /home/Mount/Develop/data/gitlab/log:/var/log/gitlab \ -d gitlab/gitlab-ce Kubernetes cluster https://hub.docker.com/r/gitlab/gitlab-ce</description></item><item><title>Elk</title><link>https://www.didida.top/docker/elk/</link><pubDate>Tue, 13 Apr 2021 21:23:59 +0800</pubDate><guid>https://www.didida.top/docker/elk/</guid><description>ELK Run docker pull sebp/elk docker run --name elk \ -p 127.0.0.1:5601:5601 \ -p 127.0.0.1:9200:9200 \ -p 127.0.0.1:5044:5044 \ -e ES_HEAP_SIZE=&amp;#34;2g&amp;#34; \ -e LS_HEAP_SIZE=&amp;#34;1g&amp;#34; \ -v /home/Develop/data/elk/es-data:/var/lib/elasticsearch \ -v /home/Develop/data/elk/logstash:/etc/logstash \ --link redis-bench:redis \ -d sebp/elk # -e TZ=&amp;#34;Asia/Shanghai&amp;#34; \ ref: https://elk-docker.readthedocs.io/#running-with-docker-compose
issue max virtual memory areas vm.max_map_count [65530] is too low, increase to at least [262144]
sudo vi /etc/sysctl.conf vm.max_map_count=655360 sudo sysctl -p ref: https://blog.csdn.net/tl1242616458/article/details/105602361/</description></item><item><title>Etcd</title><link>https://www.didida.top/docker/etcd/</link><pubDate>Tue, 13 Apr 2021 21:23:11 +0800</pubDate><guid>https://www.didida.top/docker/etcd/</guid><description>Etcd Install docker pull quay.io/coreos/etcd docker run --name etcd-node1 \ -p 127.0.0.1:2379:2379 \ -p 127.0.0.1:2380:2380 \ -e ALLOW_NONE_AUTHENTICATION=yes \ -e ETCD_NAME=node1 \ -d bitnami/etcd docker run --name e3w \ -p 127.0.0.1:8030:8080 \ --link etcd-node1:etcd \ -d soyking/e3w docker run --name etcd-node1 \ -p 127.0.0.1:2379:2379 \ -p 127.0.0.1:2380:2380 \ -e ETCD_LISTEN_CLIENT_URLS=http://127.0.0.1:2379 \ -e ETCD_LISTEN_PEER_URLS=http://127.0.0.1:2380 \ -e ETCD_INITIAL_ADVERTISE_PEER_URLS=http://127.0.0.1:2380 \ -e ALLOW_NONE_AUTHENTICATION=yes \ -e ETCD_INITIAL_CLUSTER=node1=http://127.0.0.1:2380 \ -e ETCD_NAME=node1 \ -d bitnami/etcd docker run --name etcd-node1 \ -p 127.</description></item><item><title>简介</title><link>https://www.didida.top/compiler/introduction/</link><pubDate>Sun, 11 Apr 2021 18:01:01 +0800</pubDate><guid>https://www.didida.top/compiler/introduction/</guid><description>编程语言是向人和计算机描述计算过程的记号，程序必须翻译成可以被计算机执行的形式，完成这个翻译过程的软件系统叫做编译器。
语言处理 编译器的结构 分析（analysis） 合成（synthesis） 编程语言的演变 制作编译器的科学 编译器技术的应用 编程语言基础 总结</description></item><item><title>简单的语法制导翻译</title><link>https://www.didida.top/compiler/a-simple-syntax-directed-translator/</link><pubDate>Sun, 11 Apr 2021 17:46:16 +0800</pubDate><guid>https://www.didida.top/compiler/a-simple-syntax-directed-translator/</guid><description>语法制导翻译 介绍 语法定义 语法制导翻译 语法解析 简单表达式的翻译 词法分析 符号表 中间代码生成</description></item><item><title>安装</title><link>https://www.didida.top/golang/quick-start/install/</link><pubDate>Mon, 05 Apr 2021 14:01:19 +0800</pubDate><guid>https://www.didida.top/golang/quick-start/install/</guid><description>ref: https://golang.org/</description></item><item><title>语言特性</title><link>https://www.didida.top/golang/quick-start/quick-start/</link><pubDate>Sat, 03 Apr 2021 10:50:09 +0800</pubDate><guid>https://www.didida.top/golang/quick-start/quick-start/</guid><description>Go 语言学习</description></item><item><title/><link>https://www.didida.top/kubernetes/deployment/gitlab/gitlab/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://www.didida.top/kubernetes/deployment/gitlab/gitlab/</guid><description>Gitlab ArchLinux Install sudo pacman -S postgresql-libs yay -S gitlab Configure your /etc/webapps/gitlab/gitlab.yml Set up your redis to run on /run/redis/redis.sock or configure gitlab to use redis TCP Put a secret bytestring to /etc/webapps/gitlab/secret Copy /usr/share/webapps/gitlab/config/secrets.yml.example to /etc/webapps/gitlab/secrets.yml and configure it Setup the database: $ (cd /usr/share/webapps/gitlab &amp;amp;&amp;amp; sudo -u gitlab $(cat environment | xargs) bundle exec rake gitlab:setup) Finally run the following commands to check your installation: $ (cd /usr/share/webapps/gitlab &amp;amp;&amp;amp; sudo -u gitlab $(cat environment | xargs) bundle exec rake gitlab:env:info) $ (cd /usr/share/webapps/gitlab &amp;amp;&amp;amp; sudo -u gitlab $(cat environment | xargs) bundle exec rake gitlab:check) Optional dependencies for gitlab postgresql: database backend python-docutils: reStructuredText markup language support [installed] smtp-server: mail server in order to receive mail notifications sudo cp /usr/share/webapps/gitlab/config/secrets.</description></item><item><title/><link>https://www.didida.top/kubernetes/deployment/istio/istio/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://www.didida.top/kubernetes/deployment/istio/istio/</guid><description># https://istio.io/latest/docs/examples/bookinfo/ istioctl install --set profile=demo -d manifests -y kubectl label namespace default istio-injection=enabled kubectl apply -f bookinfo.yaml kubectl get services kubectl get pods kubectl exec &amp;#34;$(kubectl get pod -l app=ratings -o jsonpath=&amp;#39;{.items[0].metadata.name}&amp;#39;)&amp;#34; -c ratings -- curl -sS productpage:9080/productpage | grep -o &amp;#34;&amp;lt;title&amp;gt;.*&amp;lt;/title&amp;gt;&amp;#34; kubectl apply -f bookinfo-gateway.yaml kubectl get gateway kubectl get svc istio-ingressgateway -n istio-system export INGRESS_PORT=$(kubectl -n istio-system get service istio-ingressgateway -o jsonpath=&amp;#39;{.spec.ports[?(@.name==&amp;#34;http2&amp;#34;)].nodePort}&amp;#39;) echo $INGRESS_PORT export INGRESS_HOST=192.168.0.10 export GATEWAY_URL=$INGRESS_HOST:$INGRESS_PORT curl -s &amp;#34;http://${GATEWAY_URL}/productpage&amp;#34; | grep -o &amp;#34;&amp;lt;title&amp;gt;.</description></item><item><title/><link>https://www.didida.top/kubernetes/deployment/istio/manifests/charts/install-openshift/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://www.didida.top/kubernetes/deployment/istio/manifests/charts/install-openshift/</guid><description>Installing Istio on OpenShift using Helm Note: Be aware of the platform setup required for OpenShift when installing Istio.
To install with Helm, you must first create the namespace that you wish to install in if the namespace does not exist already. The default namespace used is istio-system and can be created as follows:
kubectl create namespace istio-system The installation process using the Helm charts is as follows:
base chart creates cluster-wide CRDs, cluster bindings and cluster resources.</description></item><item><title/><link>https://www.didida.top/kubernetes/deployment/istio/manifests/charts/readme-helm3/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://www.didida.top/kubernetes/deployment/istio/manifests/charts/readme-helm3/</guid><description>Helm v3 support Install The Helm charts are supported both by Helm v2 and Helm v3. Please do not introduce Helm v3 specific changes as many users are still using Helm v2 and the operator is currently using the Helm v2 code to generate.
To install with Helm v3, you must first create the namespace that you wish to install in if the namespace does not exist already. The default namespace used is istio-system and can be created as follows:</description></item><item><title/><link>https://www.didida.top/kubernetes/deployment/istio/manifests/charts/readme/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://www.didida.top/kubernetes/deployment/istio/manifests/charts/readme/</guid><description>Istio Installer Note: If making any changes to the charts or values.yaml in this dir, first read UPDATING-CHARTS.md
Istio installer is a modular, &amp;lsquo;a-la-carte&amp;rsquo; installer for Istio. It is based on a fork of the Istio helm templates, refactored to increase modularity and isolation.
Goals:
Improve upgrade experience: users should be able to gradually roll upgrades, with proper canary deployments for Istio components. It should be possible to deploy a new version while keeping the stable version in place and gradually migrate apps to the new version.</description></item><item><title/><link>https://www.didida.top/kubernetes/deployment/istio/manifests/charts/updating-charts/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://www.didida.top/kubernetes/deployment/istio/manifests/charts/updating-charts/</guid><description>Upating charts and values.yaml The charts in the manifests directory are used in istioctl to generate an installation manifest. The configuration settings contained in values.yaml files and passed through the CLI are validated against a schema. Whenever making changes in the charts, it&amp;rsquo;s important to follow the below steps.
Step 0. Check that any schema change really belongs in values.yaml Is this a new parameter being added? If not, go to the next step.</description></item><item><title/><link>https://www.didida.top/kubernetes/deployment/kube/kubernetes/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://www.didida.top/kubernetes/deployment/kube/kubernetes/</guid><description>Kubernetes ArchLinux Install sudo pacman -S conntrack-tools cni-plugins socat ethtool ebtables lsmod | grep br_netfilter sudo modprobe br_netfilter echo 1 &amp;gt; /proc/sys/net/ipv4/ip_forward cat &amp;lt;&amp;lt;EOF | sudo tee /etc/modules-load.d/k8s.conf br_netfilter EOF cat &amp;lt;&amp;lt;EOF | sudo tee /etc/sysctl.d/k8s.conf net.bridge.bridge-nf-call-ip6tables = 1 net.bridge.bridge-nf-call-iptables = 1 EOF sudo sysctl --system # v1.19.8 for compatible with gitlab v13.7.4 curl -L --remote-name-all https://storage.googleapis.com/kubernetes-release/release/v1.19.8/bin/linux/amd64/\{kubeadm,kubelet,kubectl\} sudo mkdir /etc/systemd/system/kubelet.service.d sudo vi /etc/systemd/system/kubelet.service [Unit] Description=kubelet: The Kubernetes Node Agent Documentation=https://kubernetes.io/docs/home/ Wants=network-online.</description></item></channel></rss>